{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: sparl.sql.sources.partitionOverwriteMode\n",
      "22/10/04 05:05:25 WARN Utils: Your hostname, notebook resolves to a loopback address: 127.0.1.1; using 192.168.0.18 instead (on interface wlp9s0)\n",
      "22/10/04 05:05:25 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark-3.0.3/jars/spark-unsafe_2.12-3.0.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Ivy Default Cache set to: /home/walter/.ivy2/cache\n",
      "The jars for the packages stored in: /home/walter/.ivy2/jars\n",
      ":: loading settings :: url = jar:file:/opt/spark-3.0.3/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "ai.catboost#catboost-spark_3.0_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-6f97cd44-468c-4e5d-ae74-4f5f84e91b51;1.0\n",
      "\tconfs: [default]\n",
      "\tfound ai.catboost#catboost-spark_3.0_2.12;1.0.4 in central\n",
      "\tfound com.google.guava#guava;29.0-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0.1 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound org.checkerframework#checker-qual;2.11.1 in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.3.4 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.3 in central\n",
      "\tfound commons-io#commons-io;2.7 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.11 in central\n",
      "\tfound org.json4s#json4s-jackson_2.12;3.6.6 in central\n",
      "\tfound org.json4s#json4s-core_2.12;3.6.6 in central\n",
      "\tfound org.json4s#json4s-ast_2.12;3.6.6 in central\n",
      "\tfound org.json4s#json4s-scalap_2.12;3.6.6 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.8 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-databind;2.6.7.3 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.6.0 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.6.7 in central\n",
      "\tfound com.fasterxml.jackson.module#jackson-module-scala_2.12;2.6.7.1 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.6.7 in central\n",
      "\tfound com.fasterxml.jackson.module#jackson-module-paranamer;2.7.9 in central\n",
      "\tfound io.github.classgraph#classgraph;4.8.98 in central\n",
      "\tfound ai.catboost#catboost-common;1.0.4 in central\n",
      "\tfound javax.validation#validation-api;1.1.0.Final in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.25 in central\n",
      "\tfound ai.catboost#catboost-spark-macros_2.12;1.0.4 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.12 in central\n",
      ":: resolution report :: resolve 1115ms :: artifacts dl 47ms\n",
      "\t:: modules in use:\n",
      "\tai.catboost#catboost-common;1.0.4 from central in [default]\n",
      "\tai.catboost#catboost-spark-macros_2.12;1.0.4 from central in [default]\n",
      "\tai.catboost#catboost-spark_3.0_2.12;1.0.4 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.6.7 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.6.7 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.6.7.3 from central in [default]\n",
      "\tcom.fasterxml.jackson.module#jackson-module-paranamer;2.7.9 from central in [default]\n",
      "\tcom.fasterxml.jackson.module#jackson-module-scala_2.12;2.6.7.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.3.4 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.1 from central in [default]\n",
      "\tcom.google.guava#guava;29.0-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.3 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.8 from central in [default]\n",
      "\tcommons-io#commons-io;2.7 from central in [default]\n",
      "\tio.github.classgraph#classgraph;4.8.98 from central in [default]\n",
      "\tjavax.validation#validation-api;1.1.0.Final from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.11 from central in [default]\n",
      "\torg.checkerframework#checker-qual;2.11.1 from central in [default]\n",
      "\torg.json4s#json4s-ast_2.12;3.6.6 from central in [default]\n",
      "\torg.json4s#json4s-core_2.12;3.6.6 from central in [default]\n",
      "\torg.json4s#json4s-jackson_2.12;3.6.6 from central in [default]\n",
      "\torg.json4s#json4s-scalap_2.12;3.6.6 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.12 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.25 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.9.8 by [com.fasterxml.jackson.core#jackson-databind;2.6.7.3] in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.6.0 by [com.fasterxml.jackson.core#jackson-annotations;2.6.7] in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.1 by [org.scala-lang#scala-reflect;2.12.12] in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.6.7 by [com.fasterxml.jackson.core#jackson-databind;2.6.7.3] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   30  |   0   |   0   |   4   ||   26  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-6f97cd44-468c-4e5d-ae74-4f5f84e91b51\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 26 already retrieved (0kB/30ms)\n",
      "22/10/04 05:05:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .master('local')\n",
    "        .config('spark.sql.files.ignoreCorruptFiles', 'true')\n",
    "        .config('sparl.sql.sources.partitionOverwriteMode', 'dynamic')\n",
    "        .config(\"spark.jars.packages\", \"ai.catboost:catboost-spark_3.0_2.12:1.0.4\")\n",
    "        .config('spark.dynamicAllocation.enabled', 'false')\n",
    "        .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StringType, StructType\n",
    "from pyspark.ml.linalg import VectorUDT, Vectors\n",
    "from pyspark.sql import Row\n",
    "import catboost_spark as cs\n",
    "import pandas as pd\n",
    "\n",
    "# # StructField\n",
    "# PySpark StructType & StructField classes are used \n",
    "# to programmatically specify the schema to the DataFrame\n",
    "# and creating complex columns like nested struct, array and map columns. \n",
    "# StructType is a collection of StructFields that defines column name, \n",
    "# column data type, boolean to specify if the field can be nullable or not and metadata.\n",
    "\n",
    "# # pyspark.ml.linalg.vectorUDT\n",
    "# User-defined type for Vector which allows easy interaction with SQL via Dataset.\n",
    "\n",
    "# # pyspark.sql.types.StringType\n",
    "# String data type.\n",
    "\n",
    "# # Vectors\n",
    "# Factory methods for working with vectors. Note that dense vectors are simply represented as NumPy\n",
    "# array objects, so there is no need to covert them for use in MLlib.\n",
    "# For sparse vectors, the factory methods in this class create an MLlib-compatible type, \n",
    "# or users can pass in SciPy's scipy.sparse column vectors.\n",
    "\n",
    "# #Vectors.dense()\n",
    "# Create a dense vector of 64-bit floats from a Python list. Always returns a NumPy array.\n",
    "\n",
    "# # pyspark.sql.Row\n",
    "# A row in DataFrame. The fields in it can be accessed:\n",
    "\n",
    "# # cs.Pool(mi pyspark.Dataframe)\n",
    "# Mete los datos en una estructura para catboost, nada más."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# armo una lista de structField(nombre,tipo), o sea, un esquema.\n",
    "srcDataSchema = [\n",
    "    StructField(\"features\", VectorUDT()),\n",
    "    StructField(\"label\", StringType())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# armo una lista de rows, cada una con dos elementos, un vector.dense y un string\n",
    "# o sea, armo la data\n",
    "\n",
    "trainData = [\n",
    "    Row(Vectors.dense(0.1, 0.2, 0.11), \"0\"),\n",
    "    Row(Vectors.dense(0.97, 0.82, 0.33), \"1\"),\n",
    "    Row(Vectors.dense(0.13, 0.22, 0.23), \"1\"),\n",
    "    Row(Vectors.dense(0.8, 0.62, 0.0), \"0\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# me armo mi pyspark.sql.dataframe.DataFrame, \n",
    "\n",
    "# spark.sparkContext.parallelize(mi_data<lista>)\n",
    "# Distribute a local Python collection to form an RDD. Using range is \n",
    "# recommended if the input represents a range for performance.\n",
    "\n",
    "trainDf = spark.createDataFrame(spark.sparkContext.parallelize(trainData), StructType(srcDataSchema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizo un Pool, o sea, nada, lo meto en una estructura para que catboost entienda\n",
    "trainPool = cs.Pool(trainDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo mismo anterior, pero con data de evaluación\n",
    "evalData = [\n",
    "    Row(Vectors.dense(0.22, 0.33, 0.9), \"1\"),\n",
    "    Row(Vectors.dense(0.11, 0.1, 0.21), \"0\"),\n",
    "    Row(Vectors.dense(0.77, 0.0, 0.0), \"1\"),\n",
    "    Row(Vectors.dense(0.77, 0.0, 0.0), \"1\"),\n",
    "    Row(Vectors.dense(0.77, 0.0, 0.0), \"1\"),\n",
    "    Row(Vectors.dense(0.77, 0.1, 0.0), \"1\"),\n",
    "    Row(Vectors.dense(0.77, 0.4, 0.0), \"1\"),\n",
    "    Row(Vectors.dense(0.77, 0.0, 5.0), \"0\"),\n",
    "    Row(Vectors.dense(0.77, 0.0, 0.0), \"1\"),\n",
    "    Row(Vectors.dense(0.77, 0.0, 0.0), \"1\")\n",
    "]\n",
    "    \n",
    "evalDf = spark.createDataFrame(spark.sparkContext.parallelize(evalData), StructType(srcDataSchema))\n",
    "evalPool = cs.Pool(evalDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 430:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6917459\ttest: 0.6929852\tbest: 0.6929852 (0)\ttotal: 10.9ms\tremaining: 98.4ms\n",
      "1:\tlearn: 0.6903636\ttest: 0.6928148\tbest: 0.6928148 (1)\ttotal: 18.6ms\tremaining: 74.3ms\n",
      "2:\tlearn: 0.6889702\ttest: 0.6926512\tbest: 0.6926512 (2)\ttotal: 27.5ms\tremaining: 64.2ms\n",
      "3:\tlearn: 0.6875958\ttest: 0.6926693\tbest: 0.6926512 (2)\ttotal: 34.1ms\tremaining: 51.1ms\n",
      "4:\tlearn: 0.6862402\ttest: 0.6912981\tbest: 0.6912981 (4)\ttotal: 39.7ms\tremaining: 39.7ms\n",
      "5:\tlearn: 0.6848736\ttest: 0.6911419\tbest: 0.6911419 (5)\ttotal: 46.2ms\tremaining: 30.8ms\n",
      "6:\tlearn: 0.6834958\ttest: 0.6909824\tbest: 0.6909824 (6)\ttotal: 54.7ms\tremaining: 23.4ms\n",
      "7:\tlearn: 0.6821219\ttest: 0.6908251\tbest: 0.6908251 (7)\ttotal: 63.4ms\tremaining: 15.8ms\n",
      "8:\tlearn: 0.6807518\ttest: 0.6906667\tbest: 0.6906667 (8)\ttotal: 71.7ms\tremaining: 7.96ms\n",
      "9:\tlearn: 0.6783598\ttest: 0.6903791\tbest: 0.6903791 (9)\ttotal: 77.9ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6903791263\n",
      "bestIteration = 9\n",
      "\n",
      "QueryFullTime: 0.124107\n",
      "QueryExecutionTime: 0.067353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping test eval output\n",
      "0.003230997535 min passed\n",
      "+---------------+-----+--------------------+--------------------+----------+\n",
      "|       features|label|       rawPrediction|         probability|prediction|\n",
      "+---------------+-----+--------------------+--------------------+----------+\n",
      "|[0.22,0.33,0.9]|    1|[-0.0122700165425...|[0.49386529959210...|       1.0|\n",
      "|[0.11,0.1,0.21]|    0|[-0.0054910660731...|[0.49725449455736...|       1.0|\n",
      "| [0.77,0.0,0.0]|    1|[-0.0012423872599...|[0.49937880668964...|       1.0|\n",
      "| [0.77,0.0,0.0]|    1|[-0.0012423872599...|[0.49937880668964...|       1.0|\n",
      "| [0.77,0.0,0.0]|    1|[-0.0012423872599...|[0.49937880668964...|       1.0|\n",
      "| [0.77,0.1,0.0]|    1|[-0.0012423872599...|[0.49937880668964...|       1.0|\n",
      "| [0.77,0.4,0.0]|    1|[-0.0026715148175...|[0.49866424576900...|       1.0|\n",
      "| [0.77,0.0,5.0]|    0|[-0.0055689975852...|[0.49721552999291...|       1.0|\n",
      "| [0.77,0.0,0.0]|    1|[-0.0012423872599...|[0.49937880668964...|       1.0|\n",
      "| [0.77,0.0,0.0]|    1|[-0.0012423872599...|[0.49937880668964...|       1.0|\n",
      "+---------------+-----+--------------------+--------------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# instancio. Ver lista de parametros en https://catboost.ai/docs/catboost-spark/3.0_2.12/latest/api/python/api/catboost_spark.CatBoostClassifier.html#catboost_spark.CatBoostClassifier\n",
    "# allowWritingFiles: bool (para ver si escribe cosas durante training)\n",
    "\n",
    "cl = cs.CatBoostClassifier(allowWritingFiles=False, classWeightsList=[0.01,0.99], earlyStoppingRounds = 200, iterations=10, learningRate=0.01, randomSeed=100, lossFunction='Logloss') #customMetric=''\n",
    "# genero modelo\n",
    "model = cl.fit(trainPool, [evalPool])\n",
    "# predigo con el modelo\n",
    "predictions = model.transform(evalPool.data)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.22, 0.33, 0.9]</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.012270016542563773, 0.012270016542563773]</td>\n",
       "      <td>[0.49386529959210396, 0.5061347004078961]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.11, 0.1, 0.21]</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.005491066073124653, 0.005491066073124653]</td>\n",
       "      <td>[0.4972544945573653, 0.5027455054426347]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.77, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.0012423872599294427, 0.0012423872599294427]</td>\n",
       "      <td>[0.4993788066896446, 0.5006211933103554]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.77, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.0012423872599294427, 0.0012423872599294427]</td>\n",
       "      <td>[0.4993788066896446, 0.5006211933103554]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.77, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.0012423872599294427, 0.0012423872599294427]</td>\n",
       "      <td>[0.4993788066896446, 0.5006211933103554]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.77, 0.1, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.0012423872599294427, 0.0012423872599294427]</td>\n",
       "      <td>[0.4993788066896446, 0.5006211933103554]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.77, 0.4, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.0026715148175077133, 0.0026715148175077133]</td>\n",
       "      <td>[0.49866424576900015, 0.5013357542309999]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.77, 0.0, 5.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.005568997585267384, 0.005568997585267384]</td>\n",
       "      <td>[0.4972155299929109, 0.502784470007089]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.77, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.0012423872599294427, 0.0012423872599294427]</td>\n",
       "      <td>[0.4993788066896446, 0.5006211933103554]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.77, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.0012423872599294427, 0.0012423872599294427]</td>\n",
       "      <td>[0.4993788066896446, 0.5006211933103554]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            features label                                    rawPrediction  \\\n",
       "0  [0.22, 0.33, 0.9]     1    [-0.012270016542563773, 0.012270016542563773]   \n",
       "1  [0.11, 0.1, 0.21]     0    [-0.005491066073124653, 0.005491066073124653]   \n",
       "2   [0.77, 0.0, 0.0]     1  [-0.0012423872599294427, 0.0012423872599294427]   \n",
       "3   [0.77, 0.0, 0.0]     1  [-0.0012423872599294427, 0.0012423872599294427]   \n",
       "4   [0.77, 0.0, 0.0]     1  [-0.0012423872599294427, 0.0012423872599294427]   \n",
       "5   [0.77, 0.1, 0.0]     1  [-0.0012423872599294427, 0.0012423872599294427]   \n",
       "6   [0.77, 0.4, 0.0]     1  [-0.0026715148175077133, 0.0026715148175077133]   \n",
       "7   [0.77, 0.0, 5.0]     0    [-0.005568997585267384, 0.005568997585267384]   \n",
       "8   [0.77, 0.0, 0.0]     1  [-0.0012423872599294427, 0.0012423872599294427]   \n",
       "9   [0.77, 0.0, 0.0]     1  [-0.0012423872599294427, 0.0012423872599294427]   \n",
       "\n",
       "                                 probability  prediction  \n",
       "0  [0.49386529959210396, 0.5061347004078961]         1.0  \n",
       "1   [0.4972544945573653, 0.5027455054426347]         1.0  \n",
       "2   [0.4993788066896446, 0.5006211933103554]         1.0  \n",
       "3   [0.4993788066896446, 0.5006211933103554]         1.0  \n",
       "4   [0.4993788066896446, 0.5006211933103554]         1.0  \n",
       "5   [0.4993788066896446, 0.5006211933103554]         1.0  \n",
       "6  [0.49866424576900015, 0.5013357542309999]         1.0  \n",
       "7    [0.4972155299929109, 0.502784470007089]         1.0  \n",
       "8   [0.4993788066896446, 0.5006211933103554]         1.0  \n",
       "9   [0.4993788066896446, 0.5006211933103554]         1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardo modelo\n",
    "savedModelPath = \"/home/walter/Documents/serie-notas/z_aux/modelo_catboost/example_save_model.cbm\"\n",
    "\n",
    "model.saveNativeModel(savedModelPath)\n",
    "\n",
    "# cargo modelo nuevamente\n",
    "#loadedNativeModel = catboost_spark.CatBoostClassificationModel.loadNativeModel(savedNativeModelPath)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d71b34f375d735c8be32cbc17abc1cbe1b4bf3a9e7c70028bca9490fccc04562"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pyspark_1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
